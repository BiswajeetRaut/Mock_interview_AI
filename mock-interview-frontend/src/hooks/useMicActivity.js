import { useEffect, useRef, useState } from "react";

export default function useMicActivity(micOn) {
    const [isSpeaking, setIsSpeaking] = useState(false);

    const micRef = useRef(micOn);
    const rafRef = useRef(null);

    useEffect(() => {
        micRef.current = micOn; // keep ref updated
    }, [micOn]);

    useEffect(() => {
        let stream = null;
        let audioContext = null;
        let analyser = null;
        let dataArray = null;

        const stopAudio = async () => {
            console.log("ðŸ›‘ Stopping audio...");

            if (rafRef.current) {
                cancelAnimationFrame(rafRef.current);
                rafRef.current = null;
                console.log("ðŸ›‘ Animation frame canceled");
            }

            if (stream) {
                stream.getTracks().forEach((track) => {
                    track.stop();
                    console.log(`ðŸ›‘ Track ${track.kind} stopped`);
                });
                stream = null;
            }

            if (audioContext) {
                try {
                    await audioContext.close();
                    console.log("ðŸŽ§ AudioContext closed");
                } catch (e) {
                    console.error("âŒ Error closing AudioContext:", e);
                }
                audioContext = null;
            }

            setIsSpeaking(false);
            console.log("ðŸ”‡ Mic activity stopped");
        };

        if (!micOn) {
            stopAudio();
            return;
        }

        const setup = async () => {
            try {
                console.log("ðŸŽ¤ Requesting mic...");
                stream = await navigator.mediaDevices.getUserMedia({ audio: true });

                audioContext = new AudioContext();
                const source = audioContext.createMediaStreamSource(stream);

                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;

                dataArray = new Uint8Array(analyser.frequencyBinCount);
                source.connect(analyser);

                console.log("ðŸŽ§ Analyzer ready");

                const detect = () => {
                    if (!micRef.current) {
                        console.log("âŒ Mic off detected. Stopping loop.");
                        stopAudio();
                        return;
                    }

                    analyser.getByteFrequencyData(dataArray);
                    const volume = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;

                    console.log("ðŸ”Š Volume:", volume);

                    setIsSpeaking(volume > 18);

                    rafRef.current = requestAnimationFrame(detect);
                };

                detect();
            } catch (e) {
                console.error("âŒ Mic error:", e);
            }
        };

        setup();

        return () => {
            stopAudio();
        };
    }, [micOn]);

    return isSpeaking;
}
